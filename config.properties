####################################################################
#  Input files for the job, value can be 's3' or 'file'            #
####################################################################

#For S3 bucket, need to set AWS AccessKey, Secret Key, and name of S3 bucket, and its directory
#Note: S3 credentials need S3 Read Access Policy attached
#Note: The access key provided below is temporary and will expire soon
spark.inputfiletype=s3
spark.awsAccessKeyId=AKIAIU2G4JI7I7HOTR5X
spark.awsSecretAccessKey=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
spark.assetsFile=my-bucketXX/assets_2014-01-20_00_domU-12-31-39-01-A1-34.gz
spark.adFile=my-bucketXX/ad-events_2014-01-20_00_domU-12-31-39-01-A1-34.gz

## Uncomment to read from file
## For file, the path to local directory need to be set
#spark.inputfiletype = file
#spark.assetsFile = /tmp/assetsRaw
#spark.adFile = /tmp/adRaw

####################################################################
#  Output File Path                                                #
####################################################################
spark.outputFile = /tmp/gauravdiwanjiSparkJobs/
